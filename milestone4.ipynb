{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES/TODO:\n",
    "1. How do we handle different scoring scales?\n",
    "2. How do we handle essay set 2's \"dual-score\" method? (Scored across 2 different domains)\n",
    "3. Which crieterion do we use for evaluating our classifier?  I vote kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TODO if needed, include the words and stopwords imports\n",
    "# HOWEVER, to use them, you will need to download nltk stuff first if not done already\n",
    "# To do so, open a python shell (i.e. go to terminal and enter python), and then type\n",
    "#\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "# After this, select the words and stopwords corpuses, and download them\n",
    "\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.corpus import words\n",
    "\n",
    "# Regular expressions might be useful\n",
    "import re\n",
    "\n",
    "# Beautiful soup might be useful\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   essay_id  essay_set                                              essay  \\\n",
      "0         1          1  Dear local newspaper, I think effects computer...   \n",
      "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
      "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
      "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
      "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
      "\n",
      "   domain1_score  \n",
      "0              8  \n",
      "1              9  \n",
      "2              7  \n",
      "3             10  \n",
      "4              8  \n"
     ]
    }
   ],
   "source": [
    "# Read in training data\n",
    "# TODO For now, only includes domain1_score, i.e. ignores essay set 2's dual-score system\n",
    "train_cols = ['essay_id', 'essay_set', 'essay', 'domain1_score']\n",
    "train_df = pd.read_csv('data/training_set_rel3.tsv', delimiter='\\t', usecols=train_cols)\n",
    "print train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data!\n"
     ]
    }
   ],
   "source": [
    "# Show nothing is empty in training set\n",
    "if train_df.isnull().any().any():\n",
    "    print 'Data is missing!'\n",
    "else:\n",
    "    print 'No missing data!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   essay_id  essay_set                                              essay  \\\n",
      "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
      "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
      "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
      "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
      "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
      "\n",
      "   domain1_predictionid  \n",
      "0                  1788  \n",
      "1                  1789  \n",
      "2                  1790  \n",
      "3                  1791  \n",
      "4                  1792  \n"
     ]
    }
   ],
   "source": [
    "# Read in validation data\n",
    "# TODO For now, only includes domain1_predictionid, i.e. ignores essay set 2's dual-score system\n",
    "valid_cols = ['essay_id', 'essay_set', 'essay', 'domain1_predictionid']\n",
    "valid_df = pd.read_csv('data/valid_set.tsv', delimiter='\\t', usecols=valid_cols)\n",
    "print valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data!\n"
     ]
    }
   ],
   "source": [
    "# Show nothing is empty in validation set\n",
    "if valid_df.isnull().any().any():\n",
    "    print 'Data is missing!'\n",
    "else:\n",
    "    print 'No missing data!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prediction_id  predicted_score\n",
      "0           1788                7\n",
      "1           1789                8\n",
      "2           1790                9\n",
      "3           1791                9\n",
      "4           1792                9\n"
     ]
    }
   ],
   "source": [
    "# maps validations set domain1_predictionid to a score\n",
    "# note that scoring system is different for each essay set\n",
    "valid_scores = pd.read_csv('data/valid_sample_submission_2_column.csv', delimiter=',')\n",
    "print valid_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data!\n"
     ]
    }
   ],
   "source": [
    "# Show nothing is empty in validation scores\n",
    "if valid_scores.isnull().any().any():\n",
    "    print 'Data is missing!'\n",
    "else:\n",
    "    print 'No missing data!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returned a copy of old_df, with essays cleaned for count vectorizer\n",
    "def vectorizer_clean(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    for i in xrange(new_df.shape[0]):\n",
    "        new_df.set_value(i, 'essay', \" \".join(re.sub('[^a-zA-Z\\d\\s]', '', new_df['essay'].iloc[i]).lower().split())) \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   essay_id  essay_set                                              essay  \\\n",
      "0         1          1  dear local newspaper i think effects computers...   \n",
      "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
      "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
      "3         4          1  dear local newspaper caps1 i have found that m...   \n",
      "4         5          1  dear location1 i know having computers has a p...   \n",
      "\n",
      "   domain1_score  \n",
      "0              8  \n",
      "1              9  \n",
      "2              7  \n",
      "3             10  \n",
      "4              8  \n"
     ]
    }
   ],
   "source": [
    "# print essays cleaned for vectorizer (essay is now just lowercase words separated by space) \n",
    "vectorizer_train = vectorizer_clean(train_df)\n",
    "print vectorizer_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
