{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Beautiful soup might be useful\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.linear_model import LogisticRegressionCV as LogRegCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import discriminant_analysis as da\n",
    "from sklearn import tree\n",
    "# from sklearn.cross_validation import cross_val_predict \n",
    "# from sklearn import cross_validation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from nltk.corpus import wordnet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_regularized_scores(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    new_df['std_score'] = new_df.groupby(['essay_set'])[['score']].apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "    return new_df\n",
    "\n",
    "def create_regularization_data(old_df):\n",
    "    #getting the number of datasets\n",
    "    max_essay_set = max(old_df['essay_set'])\n",
    "    #list of the regularized values\n",
    "    regularization_data = []\n",
    "    for i in range(max_essay_set+1):\n",
    "        mean = np.mean((old_df[old_df['essay_set'] == i + 1])['score'])\n",
    "        std = np.std((old_df[old_df['essay_set'] == i + 1])['score'])\n",
    "        regularization_data.append([i + 1, mean, std])\n",
    "    return regularization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularized data for each essay set =  [[1, 8.528323051037576, 1.5381336495587767], [2, 6.749444444444444, 1.3844371990179603], [3, 1.8482039397450754, 0.8149207612821795], [4, 1.4322033898305084, 0.9395167668768533], [5, 2.4088642659279778, 0.9705520523317599], [6, 2.72, 0.970360757656664], [7, 16.062460165710643, 4.583888354164165], [8, 36.95020746887967, 5.749521294509325], [9, nan, nan]]\n",
      "\n",
      "\n",
      "   essay_id  essay_set                                              essay  \\\n",
      "0         1          1  Dear local newspaper, I think effects computer...   \n",
      "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
      "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
      "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
      "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
      "\n",
      "   score  std_score  \n",
      "0      8  -0.343483  \n",
      "1      9   0.306655  \n",
      "2      7  -0.993622  \n",
      "3     10   0.956794  \n",
      "4      8  -0.343483  \n",
      "\n",
      "\n",
      "mean and standard deviation of essay set 1 =  6.29333937739e-16 , 1.0\n",
      "mean and standard deviation of essay set 2 =  1.88614556072e-16 , 1.0\n",
      "mean and standard deviation of essay set 3 =  -8.54215629607e-17 , 1.0\n",
      "mean and standard deviation of essay set 4 =  -1.33038589561e-16 , 1.0\n",
      "mean and standard deviation of essay set 5 =  9.93357443086e-18 , 1.0\n",
      "mean and standard deviation of essay set 6 =  -5.91378797784e-16 , 1.0\n",
      "mean and standard deviation of essay set 7 =  1.32002616472e-16 , 1.0\n",
      "mean and standard deviation of essay set 8 =  -2.54905977991e-17 , 1.0\n"
     ]
    }
   ],
   "source": [
    "# Read in training data\n",
    "# Note that for essay set 2, score becomes average of 2 domain scores\n",
    "train_cols = ['essay_id', 'essay_set', 'essay', 'domain1_score', 'domain2_score']\n",
    "train_df = pd.read_csv('../../data/training_set_rel3.tsv', delimiter='\\t', usecols=train_cols)\n",
    "for i in xrange(train_df.shape[0]):\n",
    "    if not np.isnan(train_df.get_value(i, 'domain2_score')):\n",
    "        assert train_df.get_value(i, 'essay_set') == 2\n",
    "        new_val = train_df.get_value(i, 'domain1_score') + train_df.get_value(i, 'domain2_score')\n",
    "        train_df.set_value(i, 'domain1_score', new_val) \n",
    "train_df = train_df.drop('domain2_score', axis=1)\n",
    "train_df = train_df.rename(columns={'domain1_score': 'score'})\n",
    "\n",
    "################\n",
    "regularization_data = create_regularization_data(train_df)\n",
    "train_df = append_regularized_scores(train_df)\n",
    "\n",
    "print \"The regularized data for each essay set = \", regularization_data\n",
    "print \"\\n\"\n",
    "\n",
    "#print train_df[train_df['essay_set'] == 2].head()\n",
    "print train_df.head()\n",
    "print \"\\n\"\n",
    "\n",
    "#validate that the standardization works\n",
    "max_essay_set = max(train_df['essay_set'])\n",
    "for i in range (max_essay_set):\n",
    "    valid = train_df[train_df[\"essay_set\"] == i + 1][\"std_score\"]\n",
    "    print \"mean and standard deviation of essay set \" + str(i + 1) + \" = \", np.mean(valid), \",\", np.std(valid)\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   score  \n",
       "0      7  \n",
       "1      8  \n",
       "2      9  \n",
       "3      9  \n",
       "4      9  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in validation data\n",
    "valid_cols = ['essay_id', 'essay_set', 'essay', 'domain1_predictionid', 'domain2_predictionid']\n",
    "valid_df = pd.read_csv('../../data/valid_set.tsv', delimiter='\\t', usecols=valid_cols)\n",
    "valid_df['score'] = pd.Series([0] * valid_df.shape[0], index=valid_df.index)\n",
    "\n",
    "# scores are stored in separate data set, we'll put them in same one\n",
    "valid_scores = pd.read_csv('../../data/valid_sample_submission_5_column.csv', delimiter=',')\n",
    "\n",
    "# put each score in our data set, and make sure to handle essay set 2\n",
    "for i in xrange(valid_df.shape[0]):\n",
    "    dom1_predid = valid_df.get_value(i, 'domain1_predictionid')\n",
    "    row = valid_scores[valid_scores['prediction_id'] == dom1_predid]\n",
    "    score = row.get_value(row.index[0], 'predicted_score')\n",
    "    \n",
    "    dom2_predid = valid_df.get_value(i, 'domain2_predictionid')\n",
    "    if not np.isnan(dom2_predid):\n",
    "        assert valid_df.get_value(i, 'essay_set') == 2\n",
    "        rowB = valid_scores[valid_scores['prediction_id'] == dom2_predid]\n",
    "        scoreB = rowB.get_value(rowB.index[0], 'predicted_score')\n",
    "        score += scoreB\n",
    "        \n",
    "    valid_df.set_value(i, 'score', score)\n",
    "        \n",
    "valid_df = valid_df.drop(['domain1_predictionid', 'domain2_predictionid'], axis=1)\n",
    "#print valid_df[valid_df['essay_set'] == 2].head()\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returned a copy of old_df, with essays cleaned for count vectorizer\n",
    "# cleaning returns essay with only lowercase words separated by space\n",
    "def vectorizer_clean(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    for i in xrange(new_df.shape[0]):\n",
    "        new_df.set_value(i, 'essay', \" \".join(re.sub('[^a-zA-Z\\d\\s]', '', new_df['essay'].iloc[i]).lower().split())) \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper i think effects computers...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper caps1 i have found that m...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>dear location1 i know having computers has a p...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  dear local newspaper i think effects computers...   \n",
       "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
       "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
       "3         4          1  dear local newspaper caps1 i have found that m...   \n",
       "4         5          1  dear location1 i know having computers has a p...   \n",
       "\n",
       "   score  std_score  \n",
       "0      8  -0.343483  \n",
       "1      9   0.306655  \n",
       "2      7  -0.993622  \n",
       "3     10   0.956794  \n",
       "4      8  -0.343483  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print essays cleaned for vectorizer (essay is now just lowercase words separated by space) \n",
    "vectorizer_train = vectorizer_clean(train_df)\n",
    "vectorizer_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>dear organization1 caps1 more and more people ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>dear location1 time caps1 me tell you what i t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>dear local newspaper have you been spending a ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>dear readers caps1 you imagine how life would ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>dear newspaper i strongly believe that compute...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  dear organization1 caps1 more and more people ...   \n",
       "1      1789          1  dear location1 time caps1 me tell you what i t...   \n",
       "2      1790          1  dear local newspaper have you been spending a ...   \n",
       "3      1791          1  dear readers caps1 you imagine how life would ...   \n",
       "4      1792          1  dear newspaper i strongly believe that compute...   \n",
       "\n",
       "   score  \n",
       "0      7  \n",
       "1      8  \n",
       "2      9  \n",
       "3      9  \n",
       "4      9  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print essays cleaned for vectorizer (essay is now just lowercase words separated by space) \n",
    "vectorizer_valid = vectorizer_clean(valid_df)\n",
    "vectorizer_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.343' '0.3066' '-0.993' '0.9567' '-0.343']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "#Get all the text from data\n",
    "train_essays = vectorizer_train['essay'].values\n",
    "\n",
    "#Turn each text into an array of word counts\n",
    "train_vectors = vectorizer.fit_transform(train_essays).toarray()\n",
    "\n",
    "#normalizing for y\n",
    "train_std_scores = np.asarray(vectorizer_train['std_score'], dtype=\"|S6\")\n",
    "print train_std_scores[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classification Models\n",
    "\n",
    "Trying out LDA, QDA, Decision Trees, and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n"
     ]
    }
   ],
   "source": [
    "LDA = da.LinearDiscriminantAnalysis()\n",
    "QDA = da.QuadraticDiscriminantAnalysis()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# visualize data and calculuate accuracy rates\n",
    "models = [LDA, QDA, dt, rf]\n",
    "model_title = ['LDA', 'QDA', 'dt', 'rf']\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    print model_title[idx]\n",
    "    model.fit(train_vectors2, train_std_scores)\n",
    "\n",
    "    valid_vectors = vectorizer.transform(vectorizer_valid['essay'].values).toarray()\n",
    "    valid_pred_std_scores = model.predict(valid_vectors)\n",
    "    print valid_pred_std_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDA = da.LinearDiscriminantAnalysis()\n",
    "LDA.fit(train_vectors, train_std_scores)\n",
    "valid_vectors = vectorizer.transform(vectorizer_valid['essay'].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_pred_std_scores_lda = LDA.predict(valid_vectors)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"LDA predicted_scores\"] = valid_pred_std_scores_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['LDA predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_lda.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "# print stand_pred_values_l2\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_LDA'] = stand_pred_values_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC L2\n",
      "Number of correct predictions = 1282\n",
      "Total number of observations = 4218\n",
      "Score = 0.303935514462\n",
      "\n",
      "LOGISTIC L1\n",
      "Number of correct predictions = 1320\n",
      "Total number of observations = 4218\n",
      "Score = 0.312944523471\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "lda_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_lda']:\n",
    "        lda_count += 1\n",
    "        \n",
    "print \"LDA\"\n",
    "print \"Number of correct predictions =\", lda_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(lda_count) / len(valid_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input is list of words in text, output percentage spelling correct\n",
    "def percentage_correct_spelling(text):\n",
    "    text_len = len(text)\n",
    "    correct = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            if wordnet.synsets(word):\n",
    "                correct += 1\n",
    "        except:\n",
    "            correct+= 0\n",
    "    return 1. * correct / text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spelling_feature_x = []\n",
    "for train in train_essays:\n",
    "    sentence = train.split()\n",
    "    percent = percentage_correct_spelling(sentence)\n",
    "    spelling_feature_x.append([percent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.685459940652819], [0.6945107398568019], [0.6989247311827957], [0.6335877862595419], [0.6752688172043011], [0.6219512195121951], [0.6833667334669339], [0.6804979253112033], [0.7013574660633484], [0.6673306772908366]]\n"
     ]
    }
   ],
   "source": [
    "print spelling_feature_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6956521739130435], [0.6967741935483871], [0.6281179138321995], [0.6620498614958449], [0.7373068432671082], [0.6847826086956522], [0.7149220489977728], [0.6864864864864865], [0.7084745762711865], [0.6654545454545454]]\n"
     ]
    }
   ],
   "source": [
    "valid_essays = vectorizer_valid['essay'].values\n",
    "valid_spelling_x = []\n",
    "for valid in valid_essays:\n",
    "    sentence = valid.split()\n",
    "    percent = percentage_correct_spelling(sentence)\n",
    "    valid_spelling_x.append([percent])\n",
    "print valid_spelling_x[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Log Regression - spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l2 = LogReg(penalty='l2', solver='liblinear', n_jobs=4)\n",
    "xs = np.array(spelling_feature_x)\n",
    "logistic_l2.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l2 = logistic_l2.predict(valid_spelling_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L2 predicted_scores\"] = valid_pred_std_scores_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L2 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "# print stand_pred_values_l2\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l2'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Log Reg - Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l1 = LogReg(penalty='l1', solver='liblinear', n_jobs=4)\n",
    "xs = np.array(spelling_feature_x)\n",
    "logistic_l1.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l1 = logistic_l1.predict(valid_spelling_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L1 predicted_scores\"] = valid_pred_std_scores_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l1 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L1 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l1.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l1'] = stand_pred_values_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring with Spelling as Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC L2\n",
      "Number of correct predictions = 1195\n",
      "Total number of observations = 4218\n",
      "Score = 0.283309625415\n",
      "\n",
      "LOGISTIC L1\n",
      "Number of correct predictions = 1185\n",
      "Total number of observations = 4218\n",
      "Score = 0.28093883357\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "log_l1_count = 0\n",
    "log_l2_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l2']:\n",
    "        log_l2_count += 1\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l1']:\n",
    "        log_l1_count += 1\n",
    "        \n",
    "print \"LOGISTIC L2 using Feature: Spelling\"\n",
    "print \"Number of correct predictions =\", log_l2_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(log_l2_count) / len(valid_df)\n",
    "\n",
    "print \"\"\n",
    "print \"LOGISTIC L1 using Feature: Spelling\"\n",
    "print \"Number of correct predictions =\", log_l1_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(log_l1_count) / len(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_regularized_sentence_length(old_df):\n",
    "    new_df = old_df.copy()\n",
    "    new_df['std_sentence_len'] = new_df.groupby(['essay_set'])[['sentence_length']].apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "    return new_df\n",
    "\n",
    "def create_regularization_sentence_length(old_df):\n",
    "    #getting the number of datasets\n",
    "    max_essay_set = max(old_df['essay_set'])\n",
    "    #list of the regularized values\n",
    "    regularization_data = []\n",
    "    for i in range(max_essay_set+1):\n",
    "        mean = np.mean((old_df[old_df['essay_set'] == i + 1])['sentence_length'])\n",
    "        std = np.std((old_df[old_df['essay_set'] == i + 1])['sentence_length'])\n",
    "        regularization_data.append([i + 1, mean, std])\n",
    "    return regularization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(par):\n",
    "    split_sent = re.split(r'[.!?]+', par)\n",
    "    return len(split_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numOfSent_train = []\n",
    "for essay in train_df['essay']:\n",
    "    sent = sentences(essay)\n",
    "    numOfSent_train.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numOfSent_valid = []\n",
    "for essay in valid_df['essay']:\n",
    "    sent = sentences(essay)\n",
    "    numOfSent_valid.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['sentence_length'] = numOfSent_train\n",
    "valid_df['sentence_length'] = numOfSent_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   score  std_score  sentence_length  \n",
       "0      8  -0.343483               17  \n",
       "1      9   0.306655               21  \n",
       "2      7  -0.993622               15  \n",
       "3     10   0.956794               28  \n",
       "4      8  -0.343483               31  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   score  sentence_length  \n",
       "0      7               14  \n",
       "1      8               22  \n",
       "2      9               16  \n",
       "3      9               25  \n",
       "4      9               35  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regularization_data_sentence = create_regularization_sentence_length(train_df)\n",
    "train_df = append_regularized_sentence_length(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>std_sentence_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.761714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306655</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.327943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.993622</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956794</td>\n",
       "      <td>28</td>\n",
       "      <td>0.431156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.343483</td>\n",
       "      <td>31</td>\n",
       "      <td>0.756484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   score  std_score  sentence_length  std_sentence_len  \n",
       "0      8  -0.343483               17         -0.761714  \n",
       "1      9   0.306655               21         -0.327943  \n",
       "2      7  -0.993622               15         -0.978600  \n",
       "3     10   0.956794               28          0.431156  \n",
       "4      8  -0.343483               31          0.756484  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l2 = LogReg(penalty='l2', solver='liblinear', n_jobs=4)\n",
    "xs = [[x] for x in np.array(train_df['sentence_length'])]\n",
    "logistic_l2.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['sentence_length']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data_sentence[i][2]) + (regularization_data_sentence[i][1])))\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['new_sentence_length_std'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_x = [[x] for x in np.array(valid_df['new_sentence_length_std'])]\n",
    "valid_pred_std_scores_l2 = logistic_l2.predict(valid_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L2 predicted_scores\"] = valid_pred_std_scores_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l2 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L2 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l2.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "# print stand_pred_values_l2\n",
    "\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l2'] = stand_pred_values_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_l1 = LogReg(penalty='l1', solver='liblinear', n_jobs=4)\n",
    "logistic_l1.fit(xs, train_std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My guess is we will want to denormalize these scores for quadratic weighted k\n",
    "valid_pred_std_scores_l1 = logistic_l1.predict(valid_x)\n",
    "# Appending predicted scores to validation data set\n",
    "valid_df[\"Log_L1 predicted_scores\"] = valid_pred_std_scores_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denormalizing the values and placing them into the stand_pred_values array\n",
    "stand_pred_values_l1 = []\n",
    "for i in range(max_essay_set):\n",
    "    current_set = valid_df[valid_df['essay_set'] == i + 1]['Log_L1 predicted_scores']\n",
    "    for value in current_set:\n",
    "        stand_pred_values_l1.append(int(float(value) * float(regularization_data[i][2]) + (regularization_data[i][1])))\n",
    "#adding the denormalizede predicted values to the valid_df dataset\n",
    "valid_df['newly_predicted_scores_log_l1'] = stand_pred_values_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring using Log Regression - Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC L2 using Feature: Number of Sentences\n",
      "Number of correct predictions = 1533\n",
      "Total number of observations = 4218\n",
      "Score = 0.363442389758\n",
      "\n",
      "LOGISTIC L1 using Feature: Number of Sentences\n",
      "Number of correct predictions = 1534\n",
      "Total number of observations = 4218\n",
      "Score = 0.363679468943\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "#   Scoring   #\n",
    "###############\n",
    "\n",
    "#Scoring the predicted values with the actual values\n",
    "log_l1_count = 0\n",
    "log_l2_count = 0\n",
    "for i in range(len(valid_df)):\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l2']:\n",
    "        log_l2_count += 1\n",
    "    if valid_df.iloc[i]['score'] == valid_df.iloc[i]['newly_predicted_scores_log_l1']:\n",
    "        log_l1_count += 1\n",
    "        \n",
    "print \"LOGISTIC L2 using Feature: Number of Sentences\"\n",
    "print \"Number of correct predictions =\", log_l2_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(log_l2_count) / len(valid_df)\n",
    "\n",
    "print \"\"\n",
    "print \"LOGISTIC L1 using Feature: Number of Sentences\"\n",
    "print \"Number of correct predictions =\", log_l1_count\n",
    "print \"Total number of observations =\", len(valid_df)\n",
    "print \"Score =\", float(log_l1_count) / len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
